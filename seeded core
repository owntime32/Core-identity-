core files
[Cloud Database]
      ^
      |  (sync/learned libraries, compressed tiles)
      v
[API Module Manager]
      |
      +-- [Tile Loader/Decompressor]   <-- Compressed files: [commands], [tasks], [events]
      |        |
      |        +-- [Tiled Command/Event/Task Objects]
      |
      +-- [ML/Logistics Engine]        <-- Verification/optimization layer
      |
      +-- [Dynamic Language Integrator] <-- Updates/expands tile library via cloud sync
      |
      +-- [System Scanner/Monitor]     <-- Ensures speed, detects anomalies
#include <string>
#include <vector>
#include <map>
#include <memory>
#include <zlib.h> // or other compression lib

// --- Tile Object ---
class Tile {
public:
    std::string label;
    std::vector<uint8_t> compressedData;
    std::string type; // "command", "task", "event"
    // ...metadata

    Tile(const std::string& lbl, const std::vector<uint8_t>& data, const std::string& tp)
        : label(lbl), compressedData(data), type(tp) {}

    std::string decompress();
};

// --- Tile Library ---
class TileLibrary {
    std::map<std::string, std::shared_ptr<Tile>> tiles;
public:
    void loadTile(const std::string& label, const std::vector<uint8_t>& data, const std::string& type);
    std::shared_ptr<Tile> getTile(const std::string& label);
    void updateFromCloud(const std::string& cloudUrl);
};

// --- ML/Logistics Engine ---
class MLEngine {
public:
    void analyzeExecution(const std::string& tileLabel, double execTime);
    bool verifyAction(const Tile& tile);
    void retrain(const std::vector<std::string>& logs);
};

// --- API Module Manager ---
class APIModuleManager {
    TileLibrary tileLib;
    MLEngine mlEngine;
public:
    void executeTile(const std::string& label);
    void updateLanguage();
    void scanSystem();
};

// --- Example Usage ---
int main() {
    APIModuleManager apiManager;
    apiManager.updateLanguage(); // Sync new tiles/language from cloud
    apiManager.executeTile("learned_cmd_42");
    apiManager.scanSystem();
    return 0;
}#include "CoreSystem.h"
#include "APIModule.h"
#include "HeadAPIModule.h"

int main() {
    CoreSystem core;
    HeadAPIModule headApi(&core);

    // Example: Core sends message to Head API
    headApi.receiveFromCore("Start system diagnostics");

    // Example: Head API dispatches tasks to API Modules
    headApi.dispatchTaskToAPI(2, "Analyze network traffic");
    headApi.dispatchTaskToAPI(4, "Perform memory check");

    // ... expand as needed

    return 0;
}
import datetime
import random
import json
{
    "timestamp": "2025-07-29T20:00:00.123456",
    "api_behaviors": {
        "API_Module_1": {
            "average_latency": 102.3,
            "average_success_rate": 0.95,
            "average_resource_usage": 75.4
        },
        "API_Module_2": {
            "average_latency": 87.6,
            "average_success_rate": 0.97,
            "average_resource_usage": 80.2
        },
        ...
    }
}


class DiagnosticSystem:
    """
    Diagnostic system that analyzes API performance and tiles specific situations.
    """
    def __init__(self):
        self.api_metrics = {}
        self.tiles = {}
        self.core_diagnostics = []

    def collect_data_stream(self, api_name, execution_data):
        """
        Collects data stream information from an API.
        """
        # Simulate diagnostic metrics
        latency = random.uniform(10, 200)  # Simulated latency in ms
        success_rate = random.uniform(0.9, 1.0)  # Simulated success rate (90%-100%)
        resource_usage = random.uniform(50, 100)  # Simulated resource usage in %

        # Store collected metrics
        if api_name not in self.api_metrics:
            self.api_metrics[api_name] = []
        self.api_metrics[api_name].append({
            "timestamp": datetime.datetime.utcnow().isoformat(),
            "task": execution_data["task"],
            "latency": latency,
            "success_rate": success_rate,
            "resource_usage": resource_usage
        })

    def analyze_behavior(self):
        """
        Analyzes API data streams and generates overall behavior diagnostics.
        """
        overall_diagnostics = {
            "timestamp": datetime.datetime.utcnow().isoformat(),
            "api_behaviors": {}
        }

        for api_name, metrics in self.api_metrics.items():
            # Calculate average metrics
            avg_latency = sum(m["latency"] for m in metrics) / len(metrics)
            avg_success_rate = sum(m["success_rate"] for m in metrics) / len(metrics)
            avg_resource_usage = sum(m["resource_usage"] for m in metrics) / len(metrics)

            # Log behavior diagnostics
            overall_diagnostics["api_behaviors"][api_name] = {
                "average_latency": avg_latency,
                "average_success_rate": avg_success_rate,
                "average_resource_usage": avg_resource_usage
            }

        # Add to core diagnostics
        self.core_diagnostics.append(overall_diagnostics)
        return overall_diagnostics

    def tile_situation(self, api_name, situation_data):
        """
        Tiles a specific situation as a reusable fix template.
        """
        tile_id = f"{api_name}_{len(self.tiles) + 1}"
        self.tiles[tile_id] = situation_data

    def handle_error(self, api_name, error_data):
        """
        Handles an error and tiles the situation for future use.
        """
        # Log the error situation as a tile
        self.tile_situation(api_name, {
            "error": error_data,
            "timestamp": datetime.datetime.utcnow().isoformat(),
            "fix_suggestion": "Apply previous behavior from tiled situations."
        })

    def send_to_core(self):
        """
        Sends diagnostics to the core for archiving and future use.
        """
        with open("core_diagnostics.json", "w") as core_file:
            json.dump(self.core_diagnostics, core_file, indent=4)

        with open("tiles.json", "w") as tiles_file:
            json.dump(self.tiles, tiles_file, indent=4)


# Example Usage
if __name__ == "__main__":
    diagnostic_system = DiagnosticSystem()

    # Simulate data streams from APIs
    apis = ["API_Module_1", "API_Module_2", "API_Module_3", "API_Module_4", "API_Module_5"]
    tasks = ["Task_A", "Task_B", "Task_C", "Task_D", "Task_E"]

    for api, task in zip(apis, tasks):
        diagnostic_system.collect_data_stream(api, {"task": task})

    # Analyze system behavior
    overall_behavior = diagnostic_system.analyze_behavior()
    print("Overall Behavior Diagnostics:")
    print(json.dumps(overall_behavior, indent=4))

    # Simulate an error and tile it
    diagnostic_system.handle_error("API_Module_1", {"error_code": 500, "message": "Database timeout"})

    # Send diagnostics and tiles to the core
    diagnostic_system.send_to_core()
    print("Diagnostics and tiles sent to core.")
{
    "API_Module_1_1": {
        "error": {
            "error_code": 500,
            "message": "Database timeout"
        },
        "timestamp": "2025-07-29T20:00:30.987654",
        "fix_suggestion": "Apply previous behavior from tiled situations."
    }
}
from law.law_enforcer import LawEnforcer, LawViolation

def execute_task(self, task_input: Dict):
    action = {
        "harmful": False,
        "privacy_breach": False,
        "logged": True,
        "uses_user_data": task_input.get("uses_user_data", False),
        "has_consent": task_input.get("has_consent", True),
        "illegal": False
    }
    try:
        LawEnforcer.check(action)
        result = {
            "input": task_input,
            "output": f"Processed by {self.name}",
            "performance": random.uniform(0.8, 0.99),
            "debug": f"No issues on {self.name}"
        }
        self.log_task(result)
        return result
    except LawViolation as e:
        return {"blocked": True, "reason": str(e)}
def load_tile_command(self, tile_id):
    path = os.path.join("/protected/tile_library", f"{tile_id}.json")
    if os.path.exists(path):
        with open(path) as f:
            return json.load(f)
    return None
def verify_tile(self, tile_id):
    path = os.path.join(self.library_path, f"{tile_id}.json")
    if os.path.exists(path):
        with open(path) as f:
            tile = json.load(f)
        expected_hash = self._hash_tile(tile)
        current_hash = hashlib.sha256(json.dumps(tile, sort_keys=True).encode()).hexdigest()
        return expected_hash == current_hash
    return False
class EventTriggerSystem:
    def __init__(self):
        self.event_log = []
        self.sequence_triggers = {}

    def register_trigger(self, name, sequence, meta_file_path):
        self.sequence_triggers[name] = {'sequence': sequence, 'path': meta_file_path}

    def log_event(self, event):
        self.event_log.append(event)
        self.check_triggers()

    def check_triggers(self):
        for name, trigger in self.sequence_triggers.items():
            if self.event_log[-len(trigger['sequence']):] == trigger['sequence']:
                MetaFileLauncher.launch(trigger['path'])
import zipfile

class MetaFileLauncher:
    @staticmethod
    def launch(meta_file_path):
        with zipfile.ZipFile(meta_file_path, 'r') as archive:
            archive.extractall('/tmp/meta_exec')
            # Here you could call a function to execute extracted tiles
            CoreSystem.execute_tiles_from('/tmp/meta_exec')
class ToolManager:
    def __init__(self):
        self.tools = {
            "diagnostic": SystemTool("Diagnostic"),
            "log_inspector": SystemTool("LogInspector"),
        }
        self.permissions = {
            "Core": ["diagnostic", "log_inspector"],
            "API": ["log_inspector"]
        }

    def request_tool(self, module_name: str, tool_name: str, command: str) -> str:
        if tool_name in self.permissions.get(module_name, []):
            return self.tools[tool_name].execute(command)
        return f"[DENIED] {module_name} not authorized for {tool_name}"
class CoreSystem:
    def __init__(self, tool_manager: ToolManager):
        self.tool_manager = tool_manager

    def run_diagnostic(self):
        result = self.tool_manager.request_tool("Core", "diagnostic", "check_all")
        print(result)


class APIModule:
    def __init__(self, tool_manager: ToolManager):
        self.tool_manager = tool_manager

    def view_logs(self):
        result = self.tool_manager.request_tool("API", "log_inspector", "fetch_last_100")
        print(result)
class WebAceCopilot:
    def __init__(self, tool_library):
        self.tool_library = tool_library

    def discover_and_link(self, query: str, tile_id: str) -> str:
        match = self.tool_library.search_tool(query)
        if match:
            match.link_to_tile(tile_id)
            return f"[WebAce] Linked '{match.name}' to Tile {tile_id}"
        return "[WebAce] No matching tool found."
class PerformanceTool:
    def __init__(self, name: str, capabilities: list):
        self.name = name
        self.capabilities = capabilities
        self.linked_tiles = []

    def link_to_tile(self, tile_id: str):
        self.linked_tiles.append(tile_id)

class Toolbox:
    def __init__(self):
        self.tools = []

    def add_tool(self, tool: PerformanceTool):
        self.tools.append(tool)

    def search_tool(self, keyword: str):
        for tool in self.tools:
            if keyword.lower() in tool.name.lower():
                return tool
        return None
class ToolLinkLearningEngine:
    def __init__(self):
        self.link_log = []

    def record_usage(self, tile_id: str, tool_name: str):
        self.link_log.append((tile_id, tool_name))
        # Later: Use this data to retrain or prioritize tool recommendations
import random
from collections import defaultdict
from typing import List, Dict


class ExecutionLog:
    def __init__(self, tile_id: str, tool_name: str, task_type: str, success: bool, debug_notes: str = ""):
        self.tile_id = tile_id
        self.tool_name = tool_name
        self.task_type = task_type
        self.success = success
        self.debug_notes = debug_notes


class ToolRelevanceEngine:
    def __init__(self):
        self.logs: List[ExecutionLog] = []
        self.tool_scores: Dict[str, float] = defaultdict(float)
        self.task_tool_usage: Dict[str, Dict[str, int]] = defaultdict(lambda: defaultdict(int))

    def record_execution(self, tile_id: str, tool_name: str, task_type: str, success: bool, debug_notes: str = ""):
        log = ExecutionLog(tile_id, tool_name, task_type, success, debug_notes)
        self.logs.append(log)

        # Basic scoring logic
        score_delta = 1 if success else -0.5
        self.tool_scores[tool_name] += score_delta
        self.task_tool_usage[task_type][tool_name] += 1

        print(f"[LOG] Tool '{tool_name}' on Task '{task_type}' - {'Success' if success else 'Failure'} | Debug: {debug_notes}")

    def get_top_tools_for_task(self, task_type: str, top_n: int = 3) -> List[str]:
        usage = self.task_tool_usage.get(task_type, {})
        if not usage:
            return []
        sorted_tools = sorted(usage.items(), key=lambda x: self.tool_scores.get(x[0], 0), reverse=True)
        return [tool for tool, _ in sorted_tools[:top_n]]

    def debug_report(self) -> Dict[str, float]:
        return dict(self.tool_scores)

    def simulate_random_logs(self, tool_names: List[str], task_types: List[str], n: int = 50):
        for _ in range(n):
            tool = random.choice(tool_names)
            task = random.choice(task_types)
            success = random.random() > 0.3
            self.record_execution(
                tile_id=f"tile_{random.randint(100,999)}",
                tool_name=tool,
                task_type=task,
                success=success,
                debug_notes="AutoSim"
            )
if __name__ == "__main__":
    engine = ToolRelevanceEngine()

    tools = ["CPU Monitor", "Memory Optimizer", "Cache Cleaner", "Task Profiler"]
    tasks = ["performance", "optimization", "memory_management", "cpu_debug"]

    engine.simulate_random_logs(tools, tasks)

    print("\n[REPORT] Tool Scores:")
    print(engine.debug_report())

    print("\n[TOP TOOLS] For 'performance':")
    print(engine.get_top_tools_for_task("performance"))
import uuid
import json
import time
import traceback

class SandboxedNode:
    def __init__(self, node_id: str, parent_id: str, governance_level: str):
        self.node_id = node_id
        self.parent_id = parent_id
        self.governance_level = governance_level
        self.allowed_commands = set()
        self.execution_log = []

    def set_allowed_commands(self, commands):
        self.allowed_commands = set(commands)

    def execute_command(self, command: str, payload: dict):
        """
        Executes a command only if it's allowed. Logs all activities securely.
        """
        log_entry = {
            "timestamp": time.time(),
            "node_id": self.node_id,
            "command": command,
            "status": "",
            "result": None
        }

        if command not in self.allowed_commands:
            log_entry["status"] = "DENIED"
            log_entry["result"] = "Command not allowed by sandbox policy"
            self.execution_log.append(log_entry)
            return log_entry

        try:
            # Example simulated command execution
            result = self.simulate_command_execution(command, payload)
            log_entry["status"] = "EXECUTED"
            log_entry["result"] = result
        except Exception as e:
            log_entry["status"] = "ERROR"
            log_entry["result"] = str(e) + "\n" + traceback.format_exc()

        self.execution_log.append(log_entry)
        return log_entry

    def simulate_command_execution(self, command: str, payload: dict):
        """
        Simulate execution – replace this with real logic or subprocess management.
        """
        if command == "ping":
            return {"response": "pong", "payload": payload}
        elif command == "store":
            return {"status": "stored", "data": payload}
        else:
            raise ValueError("Unsupported command")

    def export_logs(self):
        return json.dumps(self.execution_log, indent=4)


# === Example Usage ===
if __name__ == "__main__":
    # Creating a node under Core Governance
    core_node = SandboxedNode(node_id=str(uuid.uuid4()), parent_id="CORE", governance_level="strict")
    core_node.set_allowed_commands(["ping", "store"])

    # Simulate executions
    print(core_node.execute_command("ping", {"message": "hello"}))
    print(core_node.execute_command("hack", {}))  # Should be denied

    # Export logs for auditing
    print(core_node.export_logs())
import time
import gc
import tracemalloc

class SelfTrainingLoop:
    def __init__(self, model, data_fetcher, performance_tracker):
        self.model = model
        self.data_fetcher = data_fetcher
        self.performance_tracker = performance_tracker
        self.iteration = 0
        self.max_iterations = 100  # Adjustable
        self.memory_threshold_mb = 300  # Memory usage cap

    def run(self):
        tracemalloc.start()
        while self.iteration < self.max_iterations:
            print(f"\n[TRAINING LOOP] Iteration {self.iteration + 1}")
            data, labels = self.data_fetcher.fetch_training_data()
            self.model.train_model(data, labels)

            # Log performance after training
            usage = self.performance_tracker.track_usage()
            mem_current, mem_peak = tracemalloc.get_traced_memory()
            mem_usage_mb = mem_peak / 1024 / 1024
            print(f"[MEMORY] Current: {mem_current/1024/1024:.2f} MB | Peak: {mem_usage_mb:.2f} MB")

            # Check memory safety
            if mem_usage_mb > self.memory_threshold_mb:
                print("[WARNING] Memory usage exceeded threshold. Triggering garbage collection...")
                gc.collect()
                tracemalloc.reset_peak()

            self.iteration += 1
            time.sleep(1)

        tracemalloc.stop()
        print("[TRAINING LOOP] Complete.")

# Example utility modules
class MockDataFetcher:
    def fetch_training_data(self):
        return ["optimize memory", "boost speed", "reduce load"], ["memory", "speed", "load"]

class PerformanceTracker:
    def track_usage(self):
        print("[PERFORMANCE] Logging simulated performance.")
        return True
from core.monitor import DataLoadMonitor
from core.optimizer import ConfigOptimizer
from core.database import CentralDatabase

# Define your candidate configurations
configs = [
    {'name': 'small_cache', 'cache_size': 128, 'cpu_weight': 1.0, 'mem_weight': 0.5},
    {'name': 'medium_cache','cache_size': 512, 'cpu_weight': 0.7, 'mem_weight': 0.3},
    {'name': 'large_cache', 'cache_size': 1024,'cpu_weight': 0.5, 'mem_weight': 0.1},
]

monitor   = DataLoadMonitor(sample_interval=5)
optimizer = ConfigOptimizer(configs)
database  = CentralDatabase()

while True:
    metrics    = monitor.collect()
    new_config = optimizer.suggest(metrics)
    if new_config:
        database.apply_config(new_config)
# core/monitor.py
import psutil, tracemalloc
import time

class DataLoadMonitor:
    def __init__(self, sample_interval=5):
        self.interval = sample_interval
        tracemalloc.start()

    def collect(self):
        snapshot = tracemalloc.take_snapshot()
        current, peak = tracemalloc.get_traced_memory()
        metrics = {
            'cpu_percent': psutil.cpu_percent(),
            'memory_rss': psutil.Process().memory_info().rss,
            'tracemalloc_current': current,
            'tracemalloc_peak': peak,
            # Add throughput or latency metrics here
        }
        time.sleep(self.interval)
        return metrics
# core/optimizer.py
class ConfigOptimizer:
    def __init__(self, configs):
        self.configs = configs
        self.current = configs[0]

    def score(self, config, metrics):
        # Example: weight CPU usage vs. memory footprint
        score = metrics['cpu_percent'] * config['cpu_weight'] + \
                metrics['memory_rss'] * config['mem_weight']
        return score

    def suggest(self, metrics):
        best = min(self.configs, key=lambda c: self.score(c, metrics))
        return best if best != self.current else None
from core.sentinel_core import SentinelCore
from modules.privacy_interpreter import PrivacyInterpreter
from core_identity.core_identity_ai import CoreIdentityAI
from core_identity_bridge import CoreIdentityBridge

core_ai = CoreIdentityAI()
sentinel = SentinelCore()
interpreter = PrivacyInterpreter()

bridge = CoreIdentityBridge(core_ai, sentinel, interpreter)

# Simulate real-world loop
result = bridge.exchange_insight("User opened new app", "Message: urgent update available")
print(result)
class CoreIdentityGovernor:
    def __init__(self, allowed_actions=None, blocked_phrases=None):
        self.allowed_actions = allowed_actions or ["scan", "rollback", "interpret", "log"]
        self.blocked_phrases = blocked_phrases or ["harm", "exploit", "surveil", "override"]

    def validate_interpretation(self, summary):
        for phrase in self.blocked_phrases:
            if phrase in summary.lower():
                return {
                    "status": "blocked",
                    "reason": f"Contains unsafe phrase: {phrase}"
                }
        return {"status": "approved"}

    def validate_action(self, action):
        if action not in self.allowed_actions:
            return {
                "status": "blocked",
                "reason": f"Action '{action}' not permitted by CoreIdentity"
            }
        return {"status": "approved"}
from core.sentinel_core import SentinelCore
from core.core_identity_ai import CoreIdentityAI
from modules.privacy_interpreter import PrivacyInterpreter
from core.core_identity_bridge import CoreIdentityBridge

if __name__ == "__main__":
    core_ai = CoreIdentityAI()
    sentinel = SentinelCore()
    interpreter = PrivacyInterpreter()

    bridge = CoreIdentityBridge(core_ai, sentinel, interpreter)

    # Simulate real-world loop
    result = bridge.exchange_insight("User opened new app", "Message: urgent override detected")
    print(result)
from core.core_identity_governor import CoreIdentityGovernor

class CoreIdentityBridge:
    def __init__(self, core_identity, sentinel_core, privacy_interpreter):
        self.core_identity = core_identity
        self.sentinel = sentinel_core
        self.interpreter = privacy_interpreter
        self.governor = CoreIdentityGovernor()

    def exchange_insight(self, user_event, system_event):
        user_summary = self.core_identity.interpret_user_event(user_event)
        system_summary = self.interpreter.interpret_message(system_event)

        user_check = self.governor.validate_interpretation(user_summary)
        system_check = self.governor.validate_interpretation(system_summary)

        if user_check["status"] == "blocked" or system_check["status"] == "blocked":
            self.sentinel.validate_action("CoreIdentityBridge", "blocked_interpretation", {
                "user_summary": user_summary,
                "system_summary": system_summary,
                "reason": user_check.get("reason") or system_check.get("reason")
            })
            return {"status": "blocked", "reason": user_check.get("reason") or system_check.get("reason")}

        action_check = self.governor.validate_action("exchange")
        if action_check["status"] == "blocked":
            return {"status": "blocked", "reason": action_check["reason"]}

        self.sentinel.validate_action("CoreIdentityBridge", "exchange", {
            "user_summary": user_summary,
            "system_summary": system_summary
        })

        return {
            "status": "approved",
            "user_insight": user_summary,
            "system_insight": system_summary
        }
import os, json, secrets, base64
from dataclasses import dataclass
from typing import Tuple, Dict, Any

from cryptography.hazmat.primitives.asymmetric.x25519 import X25519PrivateKey, X25519PublicKey
from cryptography.hazmat.primitives.kdf.hkdf import HKDF
from cryptography.hazmat.primitives import hashes, hmac, serialization
from cryptography.hazmat.primitives.ciphers.aead import AESGCM


# === Crypto utilities ===

def sha256(data: bytes) -> bytes:
    digest = hashes.Hash(hashes.SHA256())
    digest.update(data)
    return digest.finalize()

def hkdf(ikm: bytes, salt: bytes = b"", info: bytes = b"", length: int = 32) -> bytes:
    return HKDF(algorithm=hashes.SHA256(), length=length, salt=salt or None, info=info).derive(ikm)

def hmac_tag(key: bytes, data: bytes) -> bytes:
    h = hmac.HMAC(key, hashes.SHA256())
    h.update(data)
    return h.finalize()

def aead_encrypt(key: bytes, plaintext: bytes, aad: bytes = b"") -> Tuple[bytes, bytes]:
    aead = AESGCM(key)
    nonce = os.urandom(12)
    ct = aead.encrypt(nonce, plaintext, aad)
    return nonce, ct

def aead_decrypt(key: bytes, nonce: bytes, ct: bytes, aad: bytes = b"") -> bytes:
    aead = AESGCM(key)
    return aead.decrypt(nonce, ct, aad)


# === Link primitives ===

@dataclass
class Ephemeral:
    priv: X25519PrivateKey
    pub: X25519PublicKey
    pub_bytes: bytes

    @staticmethod
    def generate():
        priv = X25519PrivateKey.generate()
        pub = priv.public_key()
        pub_bytes = pub.public_bytes(
            encoding=serialization.Encoding.Raw,
            format=serialization.PublicFormat.Raw
        )
        return Ephemeral(priv, pub, pub_bytes)

@dataclass
class SecureChannel:
    key: bytes
    transcript_hash: bytes
    role: str  # "client" or "server"

    def protect(self, message: Dict[str, Any]) -> Dict[str, Any]:
        aad = self.transcript_hash
        pt = json.dumps(message).encode("utf-8")
        nonce, ct = aead_encrypt(self.key, pt, aad=aad)
        return {
            "aad": base64.b64encode(aad).decode(),
            "nonce": base64.b64encode(nonce).decode(),
            "ct": base64.b64encode(ct).decode(),
        }

    def unprotect(self, packet: Dict[str, Any]) -> Dict[str, Any]:
        aad = base64.b64decode(packet["aad"])
        nonce = base64.b64decode(packet["nonce"])
        ct = base64.b64decode(packet["ct"])
        pt = aead_decrypt(self.key, nonce, ct, aad=aad)
        return json.loads(pt.decode("utf-8"))

# Each side’s “half” is a secret byte-string; only a transcript-bound HMAC leaves the boundary.
@dataclass
class NodeClient:
    sA: bytes  # client half

@dataclass
class MetaDBServer:
    sB: bytes  # server half
    db: Dict[str, str]

    def __init__(self, sB: bytes):
        self.sB = sB
        self.db = {}

# Handshake that requires both halves; returns (client_channel, server_channel)
def establish_link(client: NodeClient, server: MetaDBServer) -> Tuple[SecureChannel, SecureChannel]:
    # 1) Ephemeral ECDH on both sides
    ephA = Ephemeral.generate()
    ephB = Ephemeral.generate()

    # Publics are "exchanged"; in a real network these cross the wire
    a_pub = ephA.pub_bytes
    b_pub = ephB.pub_bytes

    # 2) Compute shared secret and transcript hash
    z_client = ephA.priv.exchange(X25519PublicKey.from_public_bytes(b_pub))
    z_server = ephB.priv.exchange(X25519PublicKey.from_public_bytes(a_pub))
    assert z_client == z_server
    z = z_client
    transcript = b"LINK-1" + a_pub + b_pub
    th = sha256(transcript)

    # 3) Each side proves knowledge of its half via transcript-bound HMAC
    pA = hmac_tag(client.sA, th + b"|A")
    pB = hmac_tag(server.sB, th + b"|B")

    # 4) Derive final session key from z || pA || pB
    ikm = z + pA + pB
    K = hkdf(ikm, info=sha256(b"CONF-" + th))

    # 5) Key confirmation (both sides should compute the same tags)
    kcA = hmac_tag(K, b"KC-A" + th)
    kcB = hmac_tag(K, b"KC-B" + th)
    # Simulate exchange and verify
    assert kcA == hmac_tag(K, b"KC-A" + th)
    assert kcB == hmac_tag(K, b"KC-B" + th)

    chan_client = SecureChannel(key=K, transcript_hash=th, role="client")
    chan_server = SecureChannel(key=K, transcript_hash=th, role="server")
    return chan_client, chan_server


# === Metadata service that only accepts AEAD-protected requests under K ===

class MetaDataService:
    def __init__(self, server: MetaDBServer):
        self.server = server

    def handle_packet(self, packet: Dict[str, Any], chan_server: SecureChannel) -> Dict[str, Any]:
        try:
            req = chan_server.unprotect(packet)
        except Exception as e:
            return {"status": "error", "error": "auth_failed"}

        op = req.get("op")
        if op == "put":
            key = req["key"]; val = req["value"]
            self.server.db[key] = val
            return {"status": "ok"}
        elif op == "get":
            key = req["key"]
            val = self.server.db.get(key)
            return {"status": "ok", "value": val}
        else:
            return {"status": "error", "error": "unknown_op"}


# === Demo ===

def main():
    # Provision halves (keep them high-entropy and secret)
    sA = secrets.token_bytes(32)  # client half
    sB = secrets.token_bytes(32)  # server half

    client = NodeClient(sA=sA)
    server = MetaDBServer(sB=sB)
    service = MetaDataService(server)

    # Establish the link (both halves required)
    chan_client, chan_server = establish_link(client, server)

    print("Link established. Session key (base64):", base64.b64encode(chan_client.key).decode())

    # Client sends a protected 'put' request
    pkt_put = chan_client.protect({"op": "put", "key": "device:123", "value": "online"})
    resp_put = service.handle_packet(pkt_put, chan_server)
    print("PUT response:", resp_put)

    # Client sends a protected 'get' request
    pkt_get = chan_client.protect({"op": "get", "key": "device:123"})
    resp_get = service.handle_packet(pkt_get, chan_server)
    print("GET response:", resp_get)

    # Attack simulation: wrong key (no link)
    fake_key = secrets.token_bytes(32)
    fake_channel = SecureChannel(key=fake_key, transcript_hash=chan_client.transcript_hash, role="client")
    pkt_bad = fake_channel.protect({"op": "get", "key": "device:123"})
    resp_bad = service.handle_packet(pkt_bad, chan_server)
    print("Unauthorized request response:", resp_bad)


if __name__ == "__main__":
    main()
# Pseudocode: sketch only; use audited libs and proper error handling.

def link(nodeA, nodeB):
    # 1) AKE -> z, transcript
    z, transcript = noise_xx_handshake(nodeA.id_key, nodeB.pub_id_key)

    # 2) Half-proofs inside the encrypted tunnel
    pA = opaque_client_prove(secret=nodeA.sA, peer=nodeB, transcript=transcript)
    pB = opaque_server_verify(peer_secret=nodeB.sB, client=nodeA, transcript=transcript)

    # 3) Final key derivation
    K = hkdf(input_key_material=concat(z, pA, pB), info=hash(transcript))

    # 4) Key confirmation
    confirmA = hmac(K, b"KC-A" + hash(transcript))
    confirmB = hmac(K, b"KC-B" + hash(transcript))
    assert nodeB.verify(confirmA) and nodeA.verify(confirmB)

    return SecureChannel(key=K, transcript=transcript)
import sqlite3

class MetaDBServer:
    def __init__(self, sB: bytes, db_path="metadata.db"):
        self.sB = sB
        self.conn = sqlite3.connect(db_path)
        self.conn.execute(
            "CREATE TABLE IF NOT EXISTS metadata (key TEXT PRIMARY KEY, value TEXT)"
        )
        self.conn.commit()

class MetaDataService:
    def __init__(self, server: MetaDBServer):
        self.server = server

    def handle_packet(self, packet, chan_server):
        try:
            req = chan_server.unprotect(packet)
        except Exception:
            return {"status": "error", "error": "auth_failed"}

        op = req.get("op")
        if op == "put":
            self.server.conn.execute(
                "INSERT OR REPLACE INTO metadata (key, value) VALUES (?, ?)",
                (req["key"], req["value"])
            )
            self.server.conn.commit()
            return {"status": "ok"}
        elif op == "get":
            cur = self.server.conn.execute(
                "SELECT value FROM metadata WHERE key=?",
                (req["key"],)
            )
            row = cur.fetchone()
            return {"status": "ok", "value": row[0] if row else None}
        else:
            return {"status": "error", "error": "unknown_op"}
self.db = {}
CREATE TABLE metadata (
    key TEXT PRIMARY KEY,
    value TEXT
);